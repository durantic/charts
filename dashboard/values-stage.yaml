# Staging environment values for Durantic Dashboard
# This file overrides the default values.yaml for staging deployment

# Image configuration
image:
  tag: main  # Use main branch image for staging
  pullPolicy: Always  # Always pull latest image

# Replica configuration for staging
replicaCount: 2

# Service configuration
service:
  type: ClusterIP
  port: 80

# Ingress configuration for staging
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
  hosts:
    - host: dashboard.stage.durantic.dev
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: dashboard-stage-tls
      hosts:
        - dashboard.stage.durantic.dev

# Backend configuration for staging
backend:
  # Note: API URL is now configured at Docker build time via VITE_API_URL
  # Current build uses: https://api.stage.durantic.dev

  # Service discovery within cluster for nginx proxy configuration
  serviceName: controlplane-durantic
  servicePort: 8000
  serviceNamespace: default
  # Timeouts
  connectTimeout: 600
  sendTimeout: 600
  readTimeout: 600

# Resource limits for staging
resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

# Autoscaling for staging
autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Nginx configuration for staging
nginx:
  ssl:
    enabled: false  # TLS is handled by Ingress
  compression:
    enabled: true
    level: 6
  caching:
    enabled: true
  rateLimiting:
    enabled: true
    rate: "50r/s"
    generalRate: "500r/s"
    burst: 100
    generalBurst: 500

# Health probes tuned for staging
livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  successThreshold: 1
  failureThreshold: 3

# Pod disruption budget for staging
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Network policy for staging (allow all for now)
networkPolicy:
  enabled: false

# Monitoring for staging
monitoring:
  enabled: false  # Enable if Prometheus is available
  serviceMonitor:
    enabled: false
    interval: 30s

# Node selector for staging (if specific nodes are designated)
nodeSelector: {}

# Tolerations for staging
tolerations: []

# Affinity rules for staging - spread across nodes
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - dashboard
          topologyKey: kubernetes.io/hostname